1. OLAP operations
  a. Dimensions Tables and Fact table
  b. Roll-up
  c. Roll-down
  d. Slice
  e. Dice


3. Apriori algorithm
data = {
    'Transaction 1': ['milk', 'bread', 'butter', None],
    'Transaction 2': ['bread', 'butter', None, None],
    'Transaction 3': ['milk', 'bread', None, None],
    'Transaction 4': ['milk', 'butter', None, None],
    'Transaction 5': ['bread', 'butter', 'jam', None],
}

4. FP growth algorithm
dataset = {
    frozenset(['milk', 'bread']): 3,
    frozenset(['bread', 'butter', 'jam']): 2,
    frozenset(['milk', 'bread', 'butter', 'jam']): 2,
    frozenset(['milk', 'butter', 'jam']): 1,
}

5.  Na√Øve Bayes classifier algorithm
  Code has 2 examples:
  a. playtennis 
     data = {
    'outlook': ['sunny', 'sunny', 'overcast', 'rain', 'rain', 'rain', 'overcast', 'sunny', 'sunny', 'rain', 'sunny', 'overcast', 'overcast'],
    'temperature': ['hot', 'hot', 'hot', 'mild', 'mild', 'cool', 'cool', 'mild', 'cool', 'mild', 'mild', 'mild', 'cool'],
    'humidity': ['high', 'high', 'normal', 'normal', 'high', 'normal', 'normal', 'high', 'normal', 'normal', 'normal', 'high', 'normal'],
    'windy': ['false', 'true', 'false', 'false', 'false', 'true', 'true', 'false', 'true', 'true', 'true', 'false', 'true'],
    'playtennis': ['no', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'no']
    }
  b. Defaulted Borrower
      data = {
    'Home Owner': ['Yes', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'No'],
    'Marital Status': ['Single', 'Married', 'Single', 'Married', 'Divorced', 'Married', 'Divorced', 'Divorced', 'Single', 'Single'],
    'Annual Income': [125, 100, 70, 120, 95, 60, 220, 85, 75, 90],
    'Defaulted Borrower': ['No', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes']
    }

6. Decision tree classifier
data = {
    'age': [22, 35, 26, 27, 32],
    'income': ['high', 'medium', 'low', 'medium', 'high'],
    'student': ['no', 'yes', 'yes', 'no', 'yes'],
    'credit_rating': ['fair', 'excellent', 'fair', 'excellent', 'fair'],
    'buys_computer': ['no', 'yes', 'yes', 'no', 'yes']
}

7.1 K-means clustering algorithm
Random 500 sample points generated by using following code
X,y = make_blobs(n_samples = 500,n_features = 2,centers = 3,random_state = 23)
# For ploting points
fig = plt.figure(0)
plt.grid(True)
plt.scatter(X[:,0],X[:,1])
plt.show()

7.2 K-means clustering algorithm
Iris dataset: from sklearn.datasets import load_iris

8. DBSCAN algorithm
# Generate sample data
X, y = make_moons(n_samples=300, noise=0.1)
X = StandardScaler().fit_transform(X)

9. Outlier detection
# Creating smaple dataset
np.random.seed(42)
X_inliers=0.3*np.random.randn(100,2)
Y_inliers=np.r_[X_inliers+2,X_inliers-2]

10. Recurring patterns
# Create a random graphs
def create_graph_dataset():
    G1 = nx.Graph()
    G1.add_edges_from([(1, 2), (1, 3), (2, 3), (2, 4)])
    
    G2 = nx.Graph()
    G2.add_edges_from([(1, 2), (1, 3), (2, 4), (4, 5)])
    
    G3 = nx.Graph()
    G3.add_edges_from([(1, 2), (1, 3), (3, 4), (4, 5), (5, 6)])
    
    return [G1, G2, G3]

11. SCAN (Structural Clustering Algorithm for Networks) algorithm
# Create a sample graph
G = nx.Graph()

# Add edges to the graph
G.add_edge(1, 2)
G.add_edge(2, 3)
G.add_edge(3, 4)
G.add_edge(4, 5)
G.add_edge(5, 6)
G.add_edge(6, 1)
G.add_edge(2, 5)
G.add_edge(3, 6)

12. gSpan Algorithm
# Create sample graph
# Graph 1
graph1 = Graph(graph_id=1)
graph1.add_edge(1, 2, 'A', 'B', 'x')
graph1.add_edge(2, 3, 'B', 'C', 'y')

# Graph 2
graph2 = Graph(graph_id=2)
graph2.add_edge(1, 2, 'A', 'B', 'x')
graph2.add_edge(2, 4, 'B', 'D', 'z')
